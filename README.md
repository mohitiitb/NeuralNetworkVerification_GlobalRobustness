## Verification of Neural Networks: Specifying Global Robustness using Generative Models

We present experiments exploring the notions of global correctness and global robustness defined in our research paper:

NathanaÃ«l Fijalkow and Mohit K. Gupta
**Verification of Neural Networks: Specifying Global Robustness using Generative Models**
[arXiv link](TBA)

The experiments are in Jupter notebook format:
* [Random walk](Random_walk.ipynb)
* [Analysis of an image classifier using a generative model](Analysis.ipynb)
* [Evaluating the global correctness](Global_correctness.ipynb)
* [Searching for Realistic Adversarial Examples: black-box approach](Adversarial%20Examples%20Black-box.ipynb)
* [Searching for Realistic Adversarial Examples: white-box approach](Adversarial%20Examples%20White-box.ipynb)
* [Dependence on the generative model: disjoint training sets](EMNIST.ipynb)
#* [Replicating the experiments on the Fashion-MNIST dataset](Fashion_MNIST.ipynb)

All experiments use Tensorflow, and pre-trained models can be used (see /Models).
